{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNP0AQB7CO2vOJuuUgzpTZb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshwathiE/nlp/blob/main/nlpasmnt1_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#packages\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3bMvBqm85ZU",
        "outputId": "b24aa6ea-629c-483d-eedc-43b08341786e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#unigram\n",
        "def create_unigram_corpus(corpus):\n",
        " tokens = word_tokenize(text.lower())\n",
        " unigrams = Counter(tokens)\n",
        " return unigrams\n",
        "corpus = \"\"\"Natural Language Processing  enhances various industries by automating and refining text-based tasks.\n",
        "It is used for text classification, information extraction, and machine translation.\n",
        "NLP also powers chatbots, speech technologies, summarization, and sentiment analysis.\"\"\"\n",
        "unigram_corpus = create_unigram_corpus(corpus)\n",
        "print(unigram_corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDk0dD09_IDA",
        "outputId": "079dbea4-b386-4f27-aefa-60c622eb8fde"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({',': 5, 'and': 3, '.': 3, 'natural': 1, 'language': 1, 'processing': 1, 'enhances': 1, 'various': 1, 'industries': 1, 'by': 1, 'automating': 1, 'refining': 1, 'text-based': 1, 'tasks': 1, 'it': 1, 'is': 1, 'used': 1, 'for': 1, 'text': 1, 'classification': 1, 'information': 1, 'extraction': 1, 'machine': 1, 'translation': 1, 'nlp': 1, 'also': 1, 'powers': 1, 'chatbots': 1, 'speech': 1, 'technologies': 1, 'summarization': 1, 'sentiment': 1, 'analysis': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#bigram\n",
        "import nltk\n",
        "from collections import Counter\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.util import bigrams\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "corpus = \"\"\"Natural Language Processing  enhances various industries by automating and refining text-based tasks.\n",
        "It is used for text classification, information extraction, and machine translation.\n",
        "NLP also powers chatbots, speech technologies, summarization, and sentiment analysis.\"\"\"\n",
        "tokens = word_tokenize(corpus)\n",
        "tokens = [token.lower() for token in tokens]\n",
        "stop_words = set(stopwords.words('english'))\n",
        "tokens = [token for token in tokens if token.isalpha() and token not in stop_words]\n",
        "bigrams_list = list(bigrams(tokens))\n",
        "bigram_counts = Counter(bigrams_list)\n",
        "print(bigram_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ra_7qMJ-zRM",
        "outputId": "8ab5e7be-793d-49a3-a95a-17d83b5f7b24"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({('natural', 'language'): 1, ('language', 'processing'): 1, ('processing', 'enhances'): 1, ('enhances', 'various'): 1, ('various', 'industries'): 1, ('industries', 'automating'): 1, ('automating', 'refining'): 1, ('refining', 'tasks'): 1, ('tasks', 'used'): 1, ('used', 'text'): 1, ('text', 'classification'): 1, ('classification', 'information'): 1, ('information', 'extraction'): 1, ('extraction', 'machine'): 1, ('machine', 'translation'): 1, ('translation', 'nlp'): 1, ('nlp', 'also'): 1, ('also', 'powers'): 1, ('powers', 'chatbots'): 1, ('chatbots', 'speech'): 1, ('speech', 'technologies'): 1, ('technologies', 'summarization'): 1, ('summarization', 'sentiment'): 1, ('sentiment', 'analysis'): 1})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#trigram\n",
        "import nltk\n",
        "from nltk import ngrams\n",
        "from collections import Counter\n",
        "nltk.download('punkt')\n",
        "corpus = \"\"\"Natural Language Processing  enhances various industries by automating and refining text-based tasks.\n",
        "It is used for text classification, information extraction, and machine translation.\n",
        "NLP also powers chatbots, speech technologies, summarization, and sentiment analysis.\"\"\"\n",
        "tokens = nltk.word_tokenize(corpus)\n",
        "trigrams = list(ngrams(tokens, 3))\n",
        "trigram_freq = Counter(trigrams)\n",
        "for trigram, freq in trigram_freq.items():\n",
        " print(f\"{trigram}: {freq}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmFs747L9RKc",
        "outputId": "e2562e23-7944-4d85-dc8d-c56815dade75"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Natural', 'Language', 'Processing'): 1\n",
            "('Language', 'Processing', 'enhances'): 1\n",
            "('Processing', 'enhances', 'various'): 1\n",
            "('enhances', 'various', 'industries'): 1\n",
            "('various', 'industries', 'by'): 1\n",
            "('industries', 'by', 'automating'): 1\n",
            "('by', 'automating', 'and'): 1\n",
            "('automating', 'and', 'refining'): 1\n",
            "('and', 'refining', 'text-based'): 1\n",
            "('refining', 'text-based', 'tasks'): 1\n",
            "('text-based', 'tasks', '.'): 1\n",
            "('tasks', '.', 'It'): 1\n",
            "('.', 'It', 'is'): 1\n",
            "('It', 'is', 'used'): 1\n",
            "('is', 'used', 'for'): 1\n",
            "('used', 'for', 'text'): 1\n",
            "('for', 'text', 'classification'): 1\n",
            "('text', 'classification', ','): 1\n",
            "('classification', ',', 'information'): 1\n",
            "(',', 'information', 'extraction'): 1\n",
            "('information', 'extraction', ','): 1\n",
            "('extraction', ',', 'and'): 1\n",
            "(',', 'and', 'machine'): 1\n",
            "('and', 'machine', 'translation'): 1\n",
            "('machine', 'translation', '.'): 1\n",
            "('translation', '.', 'NLP'): 1\n",
            "('.', 'NLP', 'also'): 1\n",
            "('NLP', 'also', 'powers'): 1\n",
            "('also', 'powers', 'chatbots'): 1\n",
            "('powers', 'chatbots', ','): 1\n",
            "('chatbots', ',', 'speech'): 1\n",
            "(',', 'speech', 'technologies'): 1\n",
            "('speech', 'technologies', ','): 1\n",
            "('technologies', ',', 'summarization'): 1\n",
            "(',', 'summarization', ','): 1\n",
            "('summarization', ',', 'and'): 1\n",
            "(',', 'and', 'sentiment'): 1\n",
            "('and', 'sentiment', 'analysis'): 1\n",
            "('sentiment', 'analysis', '.'): 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#probablities\n",
        "import nltk\n",
        "from nltk import ngrams\n",
        "from collections import Counter\n",
        "nltk.download('punkt')\n",
        "# Sample text corpus\n",
        "text = \"\"\"Natural Language Processing  enhances various industries by automating and refining text-based tasks.\n",
        "It is used for text classification, information extraction, and machine translation .\n",
        "NLP also powers chatbots, speech technologies, summarization, and sentiment analysis.\"\"\"\n",
        "tokens = nltk.word_tokenize(text)\n",
        "bigrams = list(ngrams(tokens, 2))\n",
        "bigram_freq = Counter(bigrams)\n",
        "word_freq = Counter(tokens)\n",
        "bigram_probabilities = {}\n",
        "for (w1, w2), count in bigram_freq.items():\n",
        " prob = count / word_freq[w1]\n",
        " bigram_probabilities[(w1, w2)] = prob\n",
        "for bigram, prob in bigram_probabilities.items():\n",
        " print(f\"P({bigram[1]} | {bigram[0]}) = {prob:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBWh_wHN9foL",
        "outputId": "9061d70b-62fa-4021-b87a-ec0d3b5dbd95"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P(Language | Natural) = 1.00\n",
            "P(Processing | Language) = 1.00\n",
            "P(enhances | Processing) = 1.00\n",
            "P(various | enhances) = 1.00\n",
            "P(industries | various) = 1.00\n",
            "P(by | industries) = 1.00\n",
            "P(automating | by) = 1.00\n",
            "P(and | automating) = 1.00\n",
            "P(refining | and) = 0.33\n",
            "P(text-based | refining) = 1.00\n",
            "P(tasks | text-based) = 1.00\n",
            "P(. | tasks) = 1.00\n",
            "P(It | .) = 0.33\n",
            "P(is | It) = 1.00\n",
            "P(used | is) = 1.00\n",
            "P(for | used) = 1.00\n",
            "P(text | for) = 1.00\n",
            "P(classification | text) = 1.00\n",
            "P(, | classification) = 1.00\n",
            "P(information | ,) = 0.20\n",
            "P(extraction | information) = 1.00\n",
            "P(, | extraction) = 1.00\n",
            "P(and | ,) = 0.40\n",
            "P(machine | and) = 0.33\n",
            "P(translation | machine) = 1.00\n",
            "P(. | translation) = 1.00\n",
            "P(NLP | .) = 0.33\n",
            "P(also | NLP) = 1.00\n",
            "P(powers | also) = 1.00\n",
            "P(chatbots | powers) = 1.00\n",
            "P(, | chatbots) = 1.00\n",
            "P(speech | ,) = 0.20\n",
            "P(technologies | speech) = 1.00\n",
            "P(, | technologies) = 1.00\n",
            "P(summarization | ,) = 0.20\n",
            "P(, | summarization) = 1.00\n",
            "P(sentiment | and) = 0.33\n",
            "P(analysis | sentiment) = 1.00\n",
            "P(. | analysis) = 1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#next word predection\n",
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from collections import defaultdict\n",
        "import random\n",
        "nltk.download('punkt')\n",
        "corpus = [\n",
        "\"AI is an emerging technology\",\n",
        "\"NLP is a branch of AI\",\n",
        "\"she enjoys learning NLP\",\n",
        "\"I Love AI technology\",\n",
        "\"speech recognisation is an application of NLP\"\n",
        "]\n",
        "tokenized_corpus = [nltk.word_tokenize(sentence.lower()) for sentence in corpus]\n",
        "n = 2\n",
        "n_grams = [ngrams(sentence, n) for sentence in tokenized_corpus]\n",
        "next_word_dict = defaultdict(list)\n",
        "for sentence in n_grams:\n",
        " for n_gram in sentence:\n",
        "   prefix, next_word = n_gram[0], n_gram[1]\n",
        "   next_word_dict[prefix].append(next_word)\n",
        "def predict_next_word(prefix):\n",
        " prefix = prefix.lower()\n",
        " if prefix in next_word_dict:\n",
        "  return random.choice(next_word_dict[prefix])\n",
        " else:\n",
        "  return \"No prediction available.\"\n",
        "input_prefix = \"NLP\"\n",
        "predicted_word = predict_next_word(input_prefix)\n",
        "print(f\"Next word prediction for '{input_prefix}': {predicted_word}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AZLqW-P9yMr",
        "outputId": "503d3562-c13c-48f4-e442-508f16143a76"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Next word prediction for 'NLP': is\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}